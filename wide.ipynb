{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f13647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " feature4 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " feature5 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " feature6 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 1, 4)         40          ['feature4[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 1, 4)         80          ['feature5[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, 1, 4)         60          ['feature6[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 1, 12)        0           ['embedding_6[0][0]',            \n",
      "                                                                  'embedding_7[0][0]',            \n",
      "                                                                  'embedding_8[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 12)           0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 64)           832         ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 32)           2080        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1)            36          ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,128\n",
      "Trainable params: 3,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 2s 16ms/step - loss: 0.7147 - accuracy: 0.4725 - val_loss: 0.6970 - val_accuracy: 0.5250\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.5000 - val_loss: 0.6953 - val_accuracy: 0.5150\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.5163 - val_loss: 0.6945 - val_accuracy: 0.5050\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7005 - accuracy: 0.5213 - val_loss: 0.6947 - val_accuracy: 0.5100\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.5213 - val_loss: 0.6955 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245664e9290>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 假设你有一个包含wide和deep特征的数据集\n",
    "# 请替换下面的伪造数据为你自己的数据\n",
    "wide_features = tf.random.normal((1000, 3))\n",
    "deep_features = {\n",
    "    'feature4': tf.random.uniform((1000, 1), maxval=10, dtype=tf.int32),\n",
    "    'feature5': tf.random.uniform((1000, 1), maxval=20, dtype=tf.int32),\n",
    "    'feature6': tf.random.uniform((1000, 1), maxval=15, dtype=tf.int32)\n",
    "}\n",
    "\n",
    "labels = tf.random.uniform((1000, 1), maxval=2, dtype=tf.int32)\n",
    "\n",
    "# 定义 wide 特征的输入\n",
    "wide_inputs = Input(shape=(3,), name='wide_input')\n",
    "\n",
    "# 定义 deep 特征的输入\n",
    "deep_inputs = {feature: Input(shape=(1,), name=feature) for feature in ['feature4', 'feature5', 'feature6']}\n",
    "\n",
    "# 定义 wide 部分\n",
    "wide_branch = wide_inputs\n",
    "\n",
    "# 定义 deep 部分\n",
    "embeddings = [Embedding(input_dim=deep_features[feature].numpy().max() + 1, output_dim=4)(deep_inputs[feature]) for feature in ['feature4', 'feature5', 'feature6']]\n",
    "deep_branch = concatenate(embeddings)\n",
    "deep_branch = tf.keras.layers.Flatten()(deep_branch)\n",
    "deep_branch = Dense(64, activation='relu')(deep_branch)\n",
    "deep_branch = Dense(32, activation='relu')(deep_branch)\n",
    "\n",
    "# 合并 wide 和 deep 部分\n",
    "combined = concatenate([wide_branch, deep_branch])\n",
    "\n",
    "# 输出层\n",
    "output = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "# 编译模型\n",
    "model = Model(inputs=[wide_inputs] + list(deep_inputs.values()), outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 打印模型结构\n",
    "model.summary()\n",
    "\n",
    "# 训练模型\n",
    "model.fit([wide_features] + list(deep_features.values()), labels, epochs=5, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5721b884",
   "metadata": {},
   "source": [
    "您提供的代码是 TensorFlow 的一个很好的例子，用于构建和训练一个 Wide & Deep 模型。这段代码清晰地展示了如何分别处理 Wide 特征（线性模型部分）和 Deep 特征（嵌入和深度神经网络部分），并将它们结合起来进行训练。\n",
    "\n",
    "这里有几个关键点值得注意：\n",
    "\n",
    "1. **特征处理**：您使用了嵌入层（`Embedding`）来处理分类特征。这是一种常见的方法，用于将类别特征转换为可以被深度学习模型处理的密集向量。\n",
    "\n",
    "2. **模型结构**：Wide 部分直接使用原始特征，而 Deep 部分则通过几个隐藏层进行处理。这符合 Wide & Deep 模型的典型结构。\n",
    "\n",
    "3. **合并层**：使用 `concatenate` 将 Wide 和 Deep 部分结合起来，是构建此类模型的常规做法。\n",
    "\n",
    "4. **模型编译和训练**：您使用了 `adam` 优化器和二元交叉熵损失函数来编译模型，并对模型进行了训练。\n",
    "\n",
    "5. **模型概览**：通过调用 `model.summary()`，您可以查看模型的结构，这有助于理解各层是如何堆叠在一起的。\n",
    "\n",
    "6. **训练**：您使用了自动生成的数据来训练模型。在实际应用中，您将使用实际的数据集。\n",
    "\n",
    "您的代码是一个很好的起点。根据实际应用的需求，您可能需要对模型的架构、特征处理、训练参数等进行进一步的调整和优化。例如，您可以尝试添加更多的隐藏层，调整嵌入层的输出维度，或者尝试不同的激活函数和优化器。此外，对于实际应用中的数据，您可能还需要进行更复杂的特征工程和预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d884b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# 生成模拟数据\n",
    "num_samples = 10000  # 样本数量\n",
    "\n",
    "# Wide 特征（数值特征）\n",
    "wide_features = np.random.rand(num_samples, 3)  # 假设有3个数值特征\n",
    "\n",
    "# Deep 特征（分类特征）\n",
    "deep_features = {\n",
    "    'feature4': np.random.randint(0, 10, num_samples),  # 假设有10个不同的类别\n",
    "    'feature5': np.random.randint(0, 20, num_samples),  # 假设有20个不同的类别\n",
    "    'feature6': np.random.randint(0, 15, num_samples)   # 假设有15个不同的类别\n",
    "}\n",
    "\n",
    "# 目标变量（二元）\n",
    "labels = np.random.randint(0, 2, num_samples)\n",
    "\n",
    "# 转换为 pandas DataFrame 和 Series\n",
    "wide_features = pd.DataFrame(wide_features, columns=['wide1', 'wide2', 'wide3'])\n",
    "deep_features = pd.DataFrame(deep_features)\n",
    "labels = pd.Series(labels)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "wide_features_train, wide_features_val, deep_features_train, deep_features_val, labels_train, labels_val = train_test_split(\n",
    "    wide_features, deep_features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# 将数据转换为 TensorFlow 数据集\n",
    "def make_dataset(wide, deep, labels, batch_size=32, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({\"wide_input\": wide, \"feature4\": deep['feature4'], \"feature5\": deep['feature5'], \"feature6\": deep['feature6']}, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(labels))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "train_ds = make_dataset(wide_features_train, deep_features_train, labels_train)\n",
    "val_ds = make_dataset(wide_features_val, deep_features_val, labels_val, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a1ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.6946 - accuracy: 0.5059 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6921 - accuracy: 0.5215 - val_loss: 0.6949 - val_accuracy: 0.5040\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6914 - accuracy: 0.5264 - val_loss: 0.6956 - val_accuracy: 0.5020\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6904 - accuracy: 0.5354 - val_loss: 0.6966 - val_accuracy: 0.4965\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6898 - accuracy: 0.5356 - val_loss: 0.6958 - val_accuracy: 0.5005\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5421 - val_loss: 0.6970 - val_accuracy: 0.4965\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5458 - val_loss: 0.6991 - val_accuracy: 0.5025\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6863 - accuracy: 0.5454 - val_loss: 0.6989 - val_accuracy: 0.4940\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5499 - val_loss: 0.6994 - val_accuracy: 0.5085\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5564 - val_loss: 0.7032 - val_accuracy: 0.5040\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.5040\n",
      "Validation accuracy: 0.5040000081062317\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,            # 指定训练的轮数\n",
    "    validation_data=val_ds\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(val_ds)\n",
    "print(\"Validation accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1379bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# 生成模拟数据\n",
    "num_samples = 10000  # 样本数量\n",
    "\n",
    "# Wide 特征（数值特征）\n",
    "# 假设原来有3个特征，现在添加两个新的特征，总共5个特征\n",
    "wide_features = np.random.rand(num_samples, 5)  # 现在有5个数值特征\n",
    "\n",
    "# Deep 特征（分类特征）\n",
    "deep_features = {\n",
    "    'feature4': np.random.randint(0, 10, num_samples),\n",
    "    'feature5': np.random.randint(0, 20, num_samples),\n",
    "    'feature6': np.random.randint(0, 15, num_samples)\n",
    "}\n",
    "\n",
    "# 目标变量（二元）\n",
    "labels = np.random.randint(0, 2, num_samples)\n",
    "\n",
    "# 转换为 pandas DataFrame 和 Series\n",
    "wide_features = pd.DataFrame(wide_features, columns=['wide1', 'wide2', 'wide3', 'wide4', 'wide5'])\n",
    "deep_features = pd.DataFrame(deep_features)\n",
    "labels = pd.Series(labels)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "wide_features_train, wide_features_val, deep_features_train, deep_features_val, labels_train, labels_val = train_test_split(\n",
    "    wide_features, deep_features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# 将数据转换为 TensorFlow 数据集\n",
    "def make_dataset(wide, deep, labels, batch_size=32, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({\"wide_input\": wide, \"feature4\": deep['feature4'], \"feature5\": deep['feature5'], \"feature6\": deep['feature6']}, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(labels))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "train_ds = make_dataset(wide_features_train, deep_features_train, labels_train)\n",
    "val_ds = make_dataset(wide_features_val, deep_features_val, labels_val, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a288847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " feature4 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " feature5 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " feature6 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)        (None, 1, 4)         40          ['feature4[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_10 (Embedding)       (None, 1, 4)         80          ['feature5[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, 1, 4)         60          ['feature6[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 4)            0           ['embedding_9[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 4)            0           ['embedding_10[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 4)            0           ['embedding_11[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 12)           0           ['flatten_3[0][0]',              \n",
      "                                                                  'flatten_4[0][0]',              \n",
      "                                                                  'flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 64)           832         ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            6           ['wide_input[0][0]']             \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           2080        ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 33)           0           ['dense_13[0][0]',               \n",
      "                                                                  'dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1)            34          ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,132\n",
      "Trainable params: 3,132\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Embedding, Flatten, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 定义模型的输入\n",
    "# Wide 特征的输入\n",
    "wide_inputs = Input(shape=(5,), name='wide_input')\n",
    "\n",
    "# Deep 特征的输入\n",
    "feature4_input = Input(shape=(1,), name='feature4', dtype='int32')\n",
    "feature5_input = Input(shape=(1,), name='feature5', dtype='int32')\n",
    "feature6_input = Input(shape=(1,), name='feature6', dtype='int32')\n",
    "\n",
    "# 构建 Wide 部分\n",
    "wide_output = Dense(1, activation='relu')(wide_inputs)\n",
    "\n",
    "# 构建 Deep 部分\n",
    "# 假设每个分类特征的嵌入维度为 4\n",
    "embedding_feature4 = Embedding(input_dim=10, output_dim=4)(feature4_input)\n",
    "embedding_feature5 = Embedding(input_dim=20, output_dim=4)(feature5_input)\n",
    "embedding_feature6 = Embedding(input_dim=15, output_dim=4)(feature6_input)\n",
    "\n",
    "# 合并嵌入层的输出，并添加额外的隐藏层\n",
    "deep_output = concatenate([Flatten()(embedding_feature4), Flatten()(embedding_feature5), Flatten()(embedding_feature6)])\n",
    "deep_output = Dense(64, activation='relu')(deep_output)\n",
    "deep_output = Dense(32, activation='relu')(deep_output)\n",
    "\n",
    "# 合并 Wide 和 Deep 部分的输出\n",
    "combined = concatenate([wide_output, deep_output])\n",
    "\n",
    "# 添加输出层\n",
    "output = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "# 创建模型\n",
    "model = Model(inputs=[wide_inputs, feature4_input, feature5_input, feature6_input], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 打印模型结构\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d41f723",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6923 - val_accuracy: 0.5140\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5110 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5188 - val_loss: 0.6926 - val_accuracy: 0.5215\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5261 - val_loss: 0.6941 - val_accuracy: 0.4980\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5369 - val_loss: 0.6944 - val_accuracy: 0.5130\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5325 - val_loss: 0.6956 - val_accuracy: 0.4940\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5441 - val_loss: 0.6962 - val_accuracy: 0.5055\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6853 - accuracy: 0.5489 - val_loss: 0.7005 - val_accuracy: 0.4880\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5570 - val_loss: 0.7014 - val_accuracy: 0.4895\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6829 - accuracy: 0.5580 - val_loss: 0.7042 - val_accuracy: 0.4730\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.4730\n",
      "Validation accuracy: 0.4729999899864197\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,            # 指定训练的轮数\n",
    "    validation_data=val_ds\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(val_ds)\n",
    "print(\"Validation accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2e2b6",
   "metadata": {},
   "source": [
    "Wide & Deep 模型是一种由Google在2016年提出的深度学习模型，用于解决推荐系统等问题。该模型结合了线性模型（wide component）和深度模型（deep component）的优势，以提高模型在广义特征和深度特征之间进行有效学习的能力，从而更好地处理稀疏和高维数据。\n",
    "\n",
    "**简介：**\n",
    "- **Wide Component：** Wide 部分主要用于处理广义特征，这些特征通常是高度稀疏的，包含大量的类别型数据。Wide 部分采用线性模型，通过学习特征之间的交叉项，从而能够更好地捕捉广义特征之间的关联性。\n",
    "\n",
    "- **Deep Component：** Deep 部分主要用于处理深度特征，这些特征通常是低维稠密的，包含连续型数据或低基数的类别型数据。Deep 部分采用深度神经网络，通过多层非线性变换来学习特征的抽象表示，从而能够更好地捕捉深度特征之间的复杂关系。\n",
    "\n",
    "- **Wide & Deep 结合：** Wide & Deep 模型通过将 Wide 和 Deep 部分的输出连接在一起，通过一个全连接层进行融合，最终得到最终的预测结果。这种结合能够充分利用线性模型的记忆能力和深度模型的泛化能力，提高模型的整体性能。\n",
    "\n",
    "**计算公式：**\n",
    "Wide & Deep 模型的输出可以通过以下公式计算：\n",
    "\n",
    "\\[ \\text{output} = \\sigma\\left(\\text{wide\\_component} + \\text{deep\\_component}\\right) \\]\n",
    "\n",
    "其中，\n",
    "- \\(\\text{wide\\_component}\\) 为 Wide 部分的线性模型输出。\n",
    "- \\(\\text{deep\\_component}\\) 为 Deep 部分的神经网络输出。\n",
    "- \\(\\sigma\\) 通常为 sigmoid 函数，适用于二分类问题；或 softmax 函数，适用于多分类问题。\n",
    "\n",
    "整个模型的训练过程是通过最小化损失函数来更新模型参数，损失函数通常为二分类交叉熵（binary cross-entropy）或多分类交叉熵（categorical cross-entropy）等。 Wide & Deep 模型在推荐系统等应用中表现出色，特别适用于同时处理广义和深度特征的任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca6f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
